{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233e8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 6 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Softmax Probabilities:\n",
      "Combination: 0.4484\n",
      "Dry: 0.0036\n",
      "Normal: 0.1012\n",
      "Oily: 0.0920\n",
      "Sensitive: 0.3548\n",
      "\n",
      "‚úÖ Predicted Skin Type: NOT DETECTED RESCAN YOUR FACE (Confidence: 0.45)\n",
      "\n",
      "üîç Softmax Probabilities:\n",
      "Combination: 0.3971\n",
      "Dry: 0.0228\n",
      "Normal: 0.0444\n",
      "Oily: 0.1072\n",
      "Sensitive: 0.4285\n",
      "\n",
      "‚úÖ Predicted Skin Type: NOT DETECTED RESCAN YOUR FACE (Confidence: 0.43)\n",
      "\n",
      "üîç Softmax Probabilities:\n",
      "Combination: 0.3021\n",
      "Dry: 0.0082\n",
      "Normal: 0.0123\n",
      "Oily: 0.0538\n",
      "Sensitive: 0.6236\n",
      "\n",
      "‚úÖ Predicted Skin Type: Sensitive (Confidence: 0.62)\n",
      "\n",
      "üîç Softmax Probabilities:\n",
      "Combination: 0.3200\n",
      "Dry: 0.0072\n",
      "Normal: 0.0095\n",
      "Oily: 0.0609\n",
      "Sensitive: 0.6024\n",
      "\n",
      "‚úÖ Predicted Skin Type: Sensitive (Confidence: 0.60)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_PATH = r\"mobilenetv2_skin_type_model.keras\"\n",
    "TARGET_SIZE = (224, 224)\n",
    "FALLBACK_CLASS = 'NOT DETECTED RESCAN YOUR FACE'\n",
    "THRESHOLD = 0.5  # Fallback threshold for low confidence\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# === CLASS LABELS ===\n",
    "labels = {0: 'Combination', 1: 'Dry', 2: 'Normal', 3: 'Oily', 4: 'Sensitive'}\n",
    "\n",
    "# === MEDIAPIPE FACE DETECTOR ===\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "def preprocess_face(face_img):\n",
    "    face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    face_img = cv2.resize(face_img, TARGET_SIZE)\n",
    "    face_array = img_to_array(face_img) / 255.0  # Normalize\n",
    "    return np.expand_dims(face_array, axis=0)\n",
    "\n",
    "def give_feedback_and_predict(face):\n",
    "    input_data = preprocess_face(face)\n",
    "    preds = model.predict(input_data, verbose=0)[0]\n",
    "\n",
    "    print(\"\\nüîç Softmax Probabilities:\")\n",
    "    for i, prob in enumerate(preds):\n",
    "        print(f\"{labels[i]}: {prob:.4f}\")\n",
    "\n",
    "    top_idx = np.argmax(preds)\n",
    "    confidence = preds[top_idx]\n",
    "\n",
    "    if confidence < THRESHOLD:\n",
    "        final_label = FALLBACK_CLASS\n",
    "    else:\n",
    "        final_label = labels[top_idx]\n",
    "\n",
    "    print(f\"\\n‚úÖ Predicted Skin Type: {final_label} (Confidence: {confidence:.2f})\")\n",
    "    return final_label, preds\n",
    "\n",
    "def is_inside_oval(face_box, frame_shape, oval_center, oval_axes):\n",
    "    x, y, w, h = face_box\n",
    "    cx = x + w // 2\n",
    "    cy = y + h // 2\n",
    "    dx = (cx - oval_center[0]) / oval_axes[0]\n",
    "    dy = (cy - oval_center[1]) / oval_axes[1]\n",
    "    return (dx**2 + dy**2) <= 1.0  # Inside oval equation\n",
    "\n",
    "def check_lighting(face_img):\n",
    "    gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "    brightness = np.mean(gray)\n",
    "    return brightness > 80  # Threshold for brightness\n",
    "\n",
    "# === OPENCV CAPTURE LOOP ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_detection.FaceDetection(min_detection_confidence=0.6) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "        oval_center = (w // 2, h // 2)\n",
    "        oval_axes = (150, 180)  # Width, Height of oval\n",
    "\n",
    "        # Draw oval on frame\n",
    "        cv2.ellipse(frame, oval_center, oval_axes, 0, 0, 360, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Align your face inside the oval & press 'c' to capture\", \n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "        # Detect face\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image_rgb)\n",
    "\n",
    "        feedback_msg = \"\"\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                x = int(bbox.xmin * w)\n",
    "                y = int(bbox.ymin * h)\n",
    "                width = int(bbox.width * w)\n",
    "                height = int(bbox.height * h)\n",
    "\n",
    "                face_crop = frame[y:y+height, x:x+width]\n",
    "\n",
    "                # Alignment check\n",
    "                if not is_inside_oval((x, y, width, height), frame.shape, oval_center, oval_axes):\n",
    "                    feedback_msg = \"Align your face inside the oval\"\n",
    "                elif not check_lighting(face_crop):\n",
    "                    feedback_msg = \"Increase lighting\"\n",
    "                else:\n",
    "                    feedback_msg = \"Good alignment - Press 'c' to capture\"\n",
    "\n",
    "                cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "                # Capture and predict\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('c') and feedback_msg.startswith(\"Good\"):\n",
    "                    label, probs = give_feedback_and_predict(face_crop)\n",
    "                    cv2.putText(frame, f\"Predicted: {label}\", (10, h - 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 255), 2)\n",
    "\n",
    "        else:\n",
    "            feedback_msg = \"No Face Detected\"\n",
    "\n",
    "        # Show feedback on frame\n",
    "        cv2.putText(frame, feedback_msg, (10, h - 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if \"No\" in feedback_msg or \"Align\" in feedback_msg or \"lighting\" in feedback_msg else (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Skin Type Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == 27:  # ESC to exit\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31a29c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file selected.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tkinter import Tk, filedialog\n",
    "import mediapipe as mp\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_PATH = r\"mobilenetv2_skin_type_model.keras\"\n",
    "TARGET_SIZE = (224, 224)\n",
    "FALLBACK_CLASS = 'Normal'\n",
    "THRESHOLD = 0.2  # Only use fallback if ALL class scores are below this\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# === CLASS LABELS ===\n",
    "labels = {0: 'Combination', 1: 'Dry', 2: 'Normal', 3: 'Oily', 4: 'Sensitive'}\n",
    "\n",
    "# === MEDIAPIPE FACE DETECTOR ===\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "def preprocess_face(face_img):\n",
    "    \"\"\"Resize and normalize face image for model input.\"\"\"\n",
    "    face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "    face_img = cv2.resize(face_img, TARGET_SIZE)\n",
    "    face_array = img_to_array(face_img) / 255.0\n",
    "    return np.expand_dims(face_array, axis=0)\n",
    "\n",
    "def give_prediction(face_img):\n",
    "    \"\"\"Predict skin type from face image with improved fallback logic.\"\"\"\n",
    "    input_data = preprocess_face(face_img)\n",
    "    preds = model.predict(input_data, verbose=0)[0]\n",
    "\n",
    "    print(\"\\nüîç Softmax Probabilities:\")\n",
    "    for i, prob in enumerate(preds):\n",
    "        print(f\"{labels[i]}: {prob:.4f}\")\n",
    "\n",
    "    top_idx = np.argmax(preds)\n",
    "    max_prob = preds[top_idx]\n",
    "\n",
    "    # Fallback only if ALL probabilities are below threshold\n",
    "    if max_prob < THRESHOLD:\n",
    "        final_label = FALLBACK_CLASS\n",
    "    else:\n",
    "        final_label = labels[top_idx]\n",
    "\n",
    "    print(f\"\\n‚úÖ Predicted Skin Type: {final_label} (Confidence: {max_prob:.2f})\")\n",
    "    return final_label\n",
    "\n",
    "def predict_from_uploaded_image():\n",
    "    \"\"\"Open file dialog, detect face, predict skin type, and show labeled image.\"\"\"\n",
    "    Tk().withdraw()  # Hide main tkinter window\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select an Image\",\n",
    "        filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")]\n",
    "    )\n",
    "    if not file_path:\n",
    "        print(\"No file selected.\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(file_path)\n",
    "    if image is None:\n",
    "        print(\"Error loading image.\")\n",
    "        return\n",
    "\n",
    "    # Detect face with Mediapipe\n",
    "    with mp_face_detection.FaceDetection(min_detection_confidence=0.6) as face_detection:\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if not results.detections:\n",
    "            print(\"‚ùå No face detected in the image.\")\n",
    "            return\n",
    "\n",
    "        for detection in results.detections:\n",
    "            bbox = detection.location_data.relative_bounding_box\n",
    "            h, w, _ = image.shape\n",
    "            x = int(bbox.xmin * w)\n",
    "            y = int(bbox.ymin * h)\n",
    "            width = int(bbox.width * w)\n",
    "            height = int(bbox.height * h)\n",
    "\n",
    "            # Crop face\n",
    "            face_crop = image[y:y+height, x:x+width]\n",
    "            if face_crop.size == 0:\n",
    "                print(\"‚ùå Face region is empty.\")\n",
    "                return\n",
    "\n",
    "            # Predict skin type\n",
    "            label = give_prediction(face_crop)\n",
    "\n",
    "            # Draw box and label\n",
    "            cv2.rectangle(image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "            cv2.putText(image, f\"Skin Type: {label}\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 255), 2)\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"Skin Type Prediction\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Run standalone\n",
    "if __name__ == \"__main__\":\n",
    "    predict_from_uploaded_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4b9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully.\n",
      "\n",
      "üîç Softmax Probabilities:\n",
      "Combination: 0.0541\n",
      "Dry: 0.0002\n",
      "Normal: 0.0036\n",
      "Oily: 0.0118\n",
      "Sensitive: 0.9304\n",
      "\n",
      "‚úÖ Predicted Skin Type: Sensitive (Confidence: 0.93)\n",
      "Cleanup complete. Application closed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_PATH = r\"mobilenetv2_skin_type_model.keras\"\n",
    "TARGET_SIZE = (224, 224)\n",
    "FALLBACK_CLASS = 'Normal'\n",
    "THRESHOLD = 0.5  # Fallback threshold for low confidence\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "try:\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model file not found at: {MODEL_PATH}\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(\"‚úÖ Model loaded successfully.\")\n",
    "except (FileNotFoundError, Exception) as e:\n",
    "    print(f\"‚ùå Error loading the model: {e}\")\n",
    "    # Exit the program if the model cannot be loaded\n",
    "    exit()\n",
    "\n",
    "# === CLASS LABELS ===\n",
    "labels = {0: 'Combination', 1: 'Dry', 2: 'Normal', 3: 'Oily', 4: 'Sensitive'}\n",
    "\n",
    "# === MEDIAPIPE FACE DETECTOR ===\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "def preprocess_face(face_img):\n",
    "    \"\"\"Preprocesses a face image for model prediction.\"\"\"\n",
    "    try:\n",
    "        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        face_img = cv2.resize(face_img, TARGET_SIZE)\n",
    "        face_array = img_to_array(face_img) / 255.0  # Normalize\n",
    "        return np.expand_dims(face_array, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during face preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "def give_feedback_and_predict(face):\n",
    "    \"\"\"Makes a prediction on a cropped face and provides feedback.\"\"\"\n",
    "    input_data = preprocess_face(face)\n",
    "    if input_data is None:\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        preds = model.predict(input_data, verbose=0)[0]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during model prediction: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    print(\"\\nüîç Softmax Probabilities:\")\n",
    "    for i, prob in enumerate(preds):\n",
    "        print(f\"{labels[i]}: {prob:.4f}\")\n",
    "\n",
    "    top_idx = np.argmax(preds)\n",
    "    confidence = preds[top_idx]\n",
    "\n",
    "    if confidence < THRESHOLD:\n",
    "        final_label = FALLBACK_CLASS\n",
    "        print(f\"Low confidence ({confidence:.2f} < {THRESHOLD:.2f}). Falling back to '{FALLBACK_CLASS}'.\")\n",
    "    else:\n",
    "        final_label = labels[top_idx]\n",
    "\n",
    "    print(f\"\\n‚úÖ Predicted Skin Type: {final_label} (Confidence: {confidence:.2f})\")\n",
    "    return final_label, preds\n",
    "\n",
    "def is_inside_oval(face_box, oval_center, oval_axes):\n",
    "    \"\"\"Checks if the face bounding box is inside the oval guide.\"\"\"\n",
    "    x, y, w, h = face_box\n",
    "    cx = x + w // 2\n",
    "    cy = y + h // 2\n",
    "    dx = (cx - oval_center[0]) / oval_axes[0]\n",
    "    dy = (cy - oval_center[1]) / oval_axes[1]\n",
    "    return (dx**2 + dy**2) <= 1.0  # Inside oval equation\n",
    "\n",
    "def check_lighting(face_img):\n",
    "    \"\"\"Checks for sufficient lighting by calculating average brightness.\"\"\"\n",
    "    try:\n",
    "        gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "        brightness = np.mean(gray)\n",
    "        return brightness > 80  # Threshold for brightness\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking lighting: {e}\")\n",
    "        return False\n",
    "\n",
    "# === OPENCV CAPTURE LOOP ===\n",
    "cap = None  # Initialize cap to None\n",
    "try:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "    with mp_face_detection.FaceDetection(min_detection_confidence=0.6) as face_detection:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame. Exiting...\")\n",
    "                break\n",
    "\n",
    "            h, w, _ = frame.shape\n",
    "            oval_center = (w // 2, h // 2)\n",
    "            oval_axes = (150, 180)  # Width, Height of oval\n",
    "\n",
    "            # Draw oval on frame\n",
    "            cv2.ellipse(frame, oval_center, oval_axes, 0, 0, 360, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Align your face inside the oval & press 'c' to capture\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "            # Detect face\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image_rgb)\n",
    "\n",
    "            feedback_msg = \"\"\n",
    "            prediction_text = \"\"\n",
    "            \n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    bbox = detection.location_data.relative_bounding_box\n",
    "                    x = int(bbox.xmin * w)\n",
    "                    y = int(bbox.ymin * h)\n",
    "                    width = int(bbox.width * w)\n",
    "                    height = int(bbox.height * h)\n",
    "\n",
    "                    face_crop = frame[y:y+height, x:x+width]\n",
    "\n",
    "                    # Alignment check\n",
    "                    if not is_inside_oval((x, y, width, height), oval_center, oval_axes):\n",
    "                        feedback_msg = \"Align your face inside the oval\"\n",
    "                    elif not check_lighting(face_crop):\n",
    "                        feedback_msg = \"Increase lighting\"\n",
    "                    else:\n",
    "                        feedback_msg = \"Good alignment - Press 'c' to capture\"\n",
    "                    \n",
    "                    # Draw rectangle around the face\n",
    "                    cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "                    # Capture and predict\n",
    "                    key = cv2.waitKey(1) & 0xFF\n",
    "                    if key == ord('c') and feedback_msg.startswith(\"Good\"):\n",
    "                        label, probs = give_feedback_and_predict(face_crop)\n",
    "                        if label:\n",
    "                            prediction_text = f\"Predicted: {label}\"\n",
    "            else:\n",
    "                feedback_msg = \"No Face Detected\"\n",
    "\n",
    "            # Show feedback and prediction text on frame\n",
    "            cv2.putText(frame, feedback_msg, (10, h - 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if \"No\" in feedback_msg or \"Align\" in feedback_msg or \"lighting\" in feedback_msg else (0, 255, 0), 2)\n",
    "            \n",
    "            if prediction_text:\n",
    "                cv2.putText(frame, prediction_text, (10, h - 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"Skin Type Detection\", frame)\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:  # ESC to exit\n",
    "                break\n",
    "\n",
    "except (IOError, Exception) as e:\n",
    "    print(f\"‚ùå An error occurred: {e}\")\n",
    "finally:\n",
    "    # This block will always execute, whether an exception occurred or not\n",
    "    if cap is not None:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Cleanup complete. Application closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
